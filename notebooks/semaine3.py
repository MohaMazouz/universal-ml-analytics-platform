# -*- coding: utf-8 -*-
"""Semaine3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WEbrRgueuYHAIBW6Kn-Mr_BxV-GKVGi7
"""

import pandas as pd
import numpy as np
from datetime import datetime
from sklearn.model_selection import train_test_split
import os
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from imblearn.over_sampling import BorderlineSMOTE
import lightgbm as lgb
import warnings
from IPython.display import display

warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')
warnings.filterwarnings('ignore', category=FutureWarning)

class PaymentDelayAI:
    def __init__(self, multi_class_classifier_model=None):
        self.ml_multi_classifier = multi_class_classifier_model
        self.feature_columns = None  # Liste des colonnes features utilisées lors de l'entraînement
        self.category_names = {
            0: "Aucun Retard (ML Prediction)",
            1: "Est en Retard (ML Prediction)",
            2: "Retard Exagéré (ML Prediction)"
        }

    def predict_payment_behavior(self, df):
        df_featured = self.create_advanced_features(df.copy())

        # Préparer les features pour la prédiction
        X_pred = self.preprocess_features(df_featured)

        if X_pred is None:
            print("❌ Impossible de préparer les features pour la prédiction")
            return df_featured

        # Prédiction
        pred_cat_num = self.ml_multi_classifier.predict(X_pred)
        df_featured['business_category_prediction_number'] = pred_cat_num
        df_featured['business_category_prediction'] = df_featured['business_category_prediction_number'].map(self.category_names)

        # Calcul du risque financier simple (exemple)
        if ' T.T.C ' in df_featured.columns:
            risk_factor = df_featured['business_category_prediction_number'].map({0: 0.05, 1: 0.2, 2: 0.5}).fillna(0)
            df_featured['amount_at_risk_prediction'] = df_featured[' T.T.C '] * risk_factor
        else:
            df_featured['amount_at_risk_prediction'] = 0

        return df_featured

    def preprocess_features(self, df):
        if self.feature_columns is None:
            print("❌ feature_columns non défini")
            return None

        # Sélectionne les colonnes présentes à la fois dans df et dans feature_columns
        common_cols = [col for col in df.columns if col in self.feature_columns]
        X_pred = df[common_cols].copy()

        # Remplacer NaN numérique par la médiane
        num_cols = X_pred.select_dtypes(include=np.number).columns
        for col in num_cols:
            X_pred[col] = X_pred[col].fillna(X_pred[col].median())

        # Remplacer NaN catégorie par 'Missing'
        cat_cols = X_pred.select_dtypes(include='object').columns
        for col in cat_cols:
            X_pred[col] = X_pred[col].fillna('Missing')

        # One-hot encoding des colonnes catégorielles
        X_pred = pd.get_dummies(X_pred, columns=cat_cols, dummy_na=False)

        # Réindexer pour correspondre exactement aux colonnes d'entraînement
        X_pred = X_pred.reindex(columns=self.feature_columns, fill_value=0)

        return X_pred

    def create_advanced_features(self, df):
        # Conversion date échéance en datetime
        if 'échéance' in df.columns:
            df['échéance'] = pd.to_datetime(df['échéance'], errors='coerce')

        # Features temporelles
        df["Date d'Emission"] = pd.to_datetime(df["Date d'Emission"], errors='coerce')
        df['days_since_invoice'] = (pd.Timestamp.now() - df["Date d'Emission"]).dt.days
        df['days_to_due'] = (df['échéance'] - pd.Timestamp.now()).dt.days
        df['invoice_month'] = df["Date d'Emission"].dt.month
        df['due_day_of_week'] = df['échéance'].dt.dayofweek

        # Rolling features client (exemple avec fenêtre 5)
        cols_rolling = ['Code Client', 'Est_En_Retard', 'Jours_Retard', ' T.T.C ']
        if all(c in df.columns for c in cols_rolling):
            df_sorted = df.sort_values(by=['Code Client', "Date d'Emission"]).copy()
            client_feats = df_sorted.groupby('Code Client').rolling(window=5)[
                ['Est_En_Retard', 'Jours_Retard', ' T.T.C ']].agg(['mean', 'std', 'max', 'sum'])
            client_feats.columns = ['_'.join(x) for x in client_feats.columns]
            client_feats = client_feats.reset_index().rename(columns={'level_1': 'original_index'})
            df = df.reset_index().rename(columns={'index': 'original_index'})
            df = df.merge(client_feats.drop(columns=['Code Client']), on='original_index', how='left').drop('original_index', axis=1)
            rename_map = {
                'Est_En_Retard_mean': 'client_delay_mean_5',
                'Est_En_Retard_std': 'client_delay_std_5',
                'Jours_Retard_mean': 'client_avg_delay_5',
                'Jours_Retard_max': 'client_max_delay_5',
                ' T.T.C _mean': 'client_avg_ttc_5',
                ' T.T.C _sum': 'client_sum_ttc_5'
            }
            df.rename(columns=rename_map, inplace=True)
        else:
            print("⚠️ Colonnes nécessaires pour rolling features manquantes:", [c for c in cols_rolling if c not in df.columns])

        # Features caution
        if ' Caution ' in df.columns and ' T.T.C ' in df.columns:
            df['caution_utilization_rate'] = df[' T.T.C '] / df[' Caution '].replace(0, np.inf)
            df['caution_buffer'] = df[' Caution '] - df[' T.T.C ']
        else:
            print("⚠️ Colonnes 'Caution' ou 'T.T.C' manquantes pour features caution.")

        # Features comportementales statiques par défaut (à améliorer)
        df['payment_regularity'] = 0.8
        df['client_risk_trend'] = 0.2

        return df


# ----------------- Script principal -----------------

print("Chargement du fichier...")
excel_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '../data/BD_avec_regles_paiement_latest.xlsx'))
print(f"Chemin absolu du fichier Excel : {excel_path}")
df = pd.read_excel(excel_path)

for col in ["Date d'Emission", 'échéance', 'Date Encaissement']:
    if col in df.columns:
        df[col] = pd.to_datetime(df[col], errors='coerce')

# Création de la cible multiclasses
def new_cat(row):
    if row.get('Est_Retard_Exagéré', 0) == 1:
        return 2
    elif row.get('Est_En_Retard', 0) == 1:
        return 1
    else:
        return 0
df['nouvelle_categorie_retard'] = df.apply(new_cat, axis=1)

print("Distribution cible :")
print(df['nouvelle_categorie_retard'].value_counts())

# Création des features avancées
temp_ai = PaymentDelayAI()
df_fe = temp_ai.create_advanced_features(df.copy())

# Colonnes features utilisées
feature_cols = [
    'days_since_invoice', 'days_to_due', 'invoice_month', 'due_day_of_week',
    'client_delay_mean_5', 'client_delay_std_5', 'client_avg_delay_5',
    'client_max_delay_5', 'client_avg_ttc_5', 'client_sum_ttc_5',
    'caution_utilization_rate', 'caution_buffer', 'payment_regularity',
    'client_risk_trend', ' T.T.C ', ' H.T ', ' T.V.A ', ' T.R ',
    'Code Client', 'Client', 'Catégorie_Règle'
]
feature_cols = [c for c in feature_cols if c in df_fe.columns]

X_multi = df_fe[feature_cols].copy()
y_multi = df_fe['nouvelle_categorie_retard']

# Remplacement des NaN
for c in X_multi.select_dtypes(include=np.number).columns:
    X_multi[c].fillna(X_multi[c].median(), inplace=True)
for c in X_multi.select_dtypes(include='object').columns:
    X_multi[c].fillna('Missing', inplace=True)

# One-hot encoding
X_multi = pd.get_dummies(X_multi, columns=X_multi.select_dtypes(include='object').columns, dummy_na=False)

# Supprimer colonnes liées à 'Catégorie_Règle' si présentes
cols_to_drop = [col for col in X_multi.columns if col.startswith('Catégorie_Règle_')]
X_multi.drop(columns=cols_to_drop, inplace=True, errors='ignore')

# Split train/test stratifié
X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(
    X_multi, y_multi, test_size=0.2, random_state=42, stratify=y_multi
)

print("Taille train multi:", X_train_multi.shape)
print("Taille test multi:", X_test_multi.shape)

# SMOTE borderline pour équilibrer les classes
smote = BorderlineSMOTE(random_state=42)
X_train_bal, y_train_bal = smote.fit_resample(X_train_multi, y_train_multi)

print("Après SMOTE train:", X_train_bal.shape)
print("Répartition classes après SMOTE:", np.bincount(y_train_bal))

# Entraînement LightGBM multiclasses
lgb_multi = lgb.LGBMClassifier(objective='multiclass', num_class=3, random_state=42, n_jobs=-1)
lgb_multi.fit(X_train_bal, y_train_bal)

print("Modèle LightGBM multi-classes entraîné.")

# Évaluation sur test
y_pred = lgb_multi.predict(X_test_multi)
print(f"Accuracy test: {accuracy_score(y_test_multi, y_pred):.4f}")
print("Matrice de confusion :")
print(confusion_matrix(y_test_multi, y_pred))
print("Rapport classification :")
print(classification_report(y_test_multi, y_pred))

# Instanciation de la classe avec modèle et colonnes features
payment_ai = PaymentDelayAI(multi_class_classifier_model=lgb_multi)
payment_ai.feature_columns = X_train_multi.columns.tolist()

# Prédiction sur l'ensemble du dataframe original
df_predictions = payment_ai.predict_payment_behavior(df.copy())

print("Exemple prédictions :")
print(df_predictions[['N° Facture', 'Est_En_Retard', 'Jours_Retard',
                      'business_category_prediction_number', 'business_category_prediction',
                      'amount_at_risk_prediction']].head())
##
print("Distribution prédictions business categories :")
print(df_predictions['business_category_prediction'].value_counts())

print("\n Distribution des prédictions:")
print(df_predictions['business_category_prediction'].value_counts())

print("\n Aperçu des prédictions:")
display_cols = ['N° Facture', 'Est_En_Retard', 'Jours_Retard', ' T.T.C ',
                'business_category_prediction_number', 'business_category_prediction',
                'amount_at_risk_prediction', 'prob_class_0', 'prob_class_1', 'prob_class_2']

available_cols = [col for col in display_cols if col in df_predictions.columns]
print(df_predictions[available_cols].head(10).to_string())

print("\n Échantillons par catégorie prédite:")
for category_number in [0, 1, 2]:
    category_name = payment_ai.category_names[category_number]
    print(f"\n--- Catégorie {category_number}: {category_name} ---")
    sample_rows = df_predictions[df_predictions['business_category_prediction_number'] == category_number].head(3)
    if len(sample_rows) > 0:
        print(sample_rows[['N° Facture', 'Jours_Retard', ' T.T.C ', 'amount_at_risk_prediction']].to_string())
    else:
        print("Aucun échantillon trouvé pour cette catégorie")

# Add probability columns to df_predictions
if hasattr(lgb_multi, 'predict_proba'):
    probabilities = lgb_multi.predict_proba(payment_ai.preprocess_features(df_fe.copy()))
    df_predictions['prob_class_0'] = probabilities[:, 0]
    df_predictions['prob_class_1'] = probabilities[:, 1]
    df_predictions['prob_class_2'] = probabilities[:, 2]
else:
    print(" Le modèle ne supporte pas predict_proba. Les colonnes de probabilité ne seront pas ajoutées.")

print(f"\n MODÈLE LIGHTGBM INTÉGRÉ AVEC SUCCÈS!")
# Calculate precision for classes 1 and 2 for the final print statement
try:
    report = classification_report(y_test_multi, y_pred, output_dict=True)
    precision_classes_1_2 = (report['1']['precision'] + report['2']['precision']) / 2 * 100
    print(f" Prêt pour la production avec {precision_classes_1_2:.1f}% de précision sur les classes à risque!")
except KeyError:
    print(" Impossible de calculer la précision moyenne pour les classes 1 et 2. Vérifiez si ces classes sont présentes dans les prédictions.")
except Exception as e:
    print(f" Une erreur est survenue lors du calcul de la précision : {e}")

# ====================== NEW ADDITION ======================
# Add these functions right before the final output section

def generate_client_features_table(df_predictions):
    """Generate summary table of client features for each prediction category"""
    # Select key features to analyze
    feature_cols = [
        'Code Client', 'Client',
        ' T.T.C ', ' Caution ', 'caution_utilization_rate',
        'client_delay_mean_5', 'client_max_delay_5',
        'days_to_due', 'payment_regularity', 'client_risk_trend'
    ]

    # Filter for existing columns
    available_cols = [col for col in feature_cols if col in df_predictions.columns]

    # Create summary table
    summary_table = df_predictions.groupby('business_category_prediction')[available_cols].agg({
        ' T.T.C ': ['mean', 'max'],
        ' Caution ': 'mean',
        'caution_utilization_rate': 'mean',
        'client_delay_mean_5': 'mean',
        'client_max_delay_5': ['mean', 'max'],
        'days_to_due': 'mean',
        'payment_regularity': 'mean',
        'client_risk_trend': 'mean',
        'Code Client': 'count'
    }).rename(columns={'Code Client': 'count'})

    # Flatten multi-index columns
    summary_table.columns = [
        'Montant moyen (€)', 'Montant max (€)',
        'Caution moyenne (€)', 'Taux utilisation caution (%)',
        'Retard moyen historique (jours)',
        'Pire retard moyen historique (jours)', 'Pire retard absolu (jours)',
        'Délai moyen avant échéance (jours)',
        'Régularité paiement (0-1)', 'Risque client (0-1)',
        'Nb factures'
    ]

    # Format percentages
    summary_table['Taux utilisation caution (%)'] = summary_table['Taux utilisation caution (%)'] * 100
    for col in ['Régularité paiement (0-1)', 'Risque client (0-1)']:
        summary_table[col] = summary_table[col].round(2)

    return summary_table.sort_index()

def generate_high_risk_client_details(df_predictions, max_clients=20):
    """Generate detailed table of high-risk clients (category 2) without duplicates"""
    high_risk = df_predictions[df_predictions['business_category_prediction_number'] == 2]

    if not high_risk.empty:
        # 1. Trouver la pire facture par client (plus haut montant ou retard)
        worst_invoices = high_risk.sort_values(
            by=[' T.T.C ', 'Jours_Retard'],
            ascending=[False, False]
        ).drop_duplicates('Code Client')

        # 2. Sélectionner les colonnes pertinentes
        result = worst_invoices[[
            'Code Client', 'Client', 'N° Facture', ' T.T.C ', 'Jours_Retard',
            'client_max_delay_5', 'caution_utilization_rate', 'amount_at_risk_prediction'
        ]].rename(columns={
            ' T.T.C ': 'Montant (€)',
            'Jours_Retard': 'Retard actuel (jours)',
            'client_max_delay_5': 'Pire retard historique (jours)',
            'caution_utilization_rate': 'Taux utilisation caution',
            'amount_at_risk_prediction': 'Risque financier (€)'
        })

        # 3. Trier par risque financier décroissant
        return result.sort_values('Risque financier (€)', ascending=False).head(max_clients)

    return pd.DataFrame()

def generate_client_samples_by_category(df_predictions, n_samples=5):
    """Generate representative client samples for each prediction category."""
    samples = {}
    for category_number, category_name in PaymentDelayAI().category_names.items():
        category_df = df_predictions[df_predictions['business_category_prediction_number'] == category_number]
        if not category_df.empty:
            # Use .sample with replace=True if category size is less than n_samples
            replace = len(category_df) < n_samples
            samples[category_name] = category_df.sample(n=min(n_samples, len(category_df)), random_state=42, replace=replace)[
                ['Code Client', 'Client', 'N° Facture', ' T.T.C ', 'Jours_Retard', 'business_category_prediction']
            ]
        else:
            samples[category_name] = pd.DataFrame() # Return empty DataFrame if no samples

    return samples

def format_client_samples(samples):
    """Format the client samples for display."""
    formatted_output = ""
    for category, df_sample in samples.items():
        formatted_output += f"\n--- {category} ---\n"
        if not df_sample.empty:
            formatted_output += df_sample.to_string(index=False) + "\n"
        else:
            formatted_output += "Aucun échantillon trouvé pour cette catégorie.\n"
    return formatted_output


# Generate and display the tables
print("\n ANALYSE DES CLIENTS PAR CATÉGORIE DE RETARD")
print("--------------------------------------------")

# 1. Main summary table
client_features_table = generate_client_features_table(df_predictions)
print("\n Statistiques moyennes par catégorie:")
display(client_features_table)
# 2. Échantillons de clients par catégorie
print("\n CLIENTS REPRÉSENTATIFS PAR CATÉGORIE:")
client_samples = generate_client_samples_by_category(df_predictions, n_samples=5)
print(format_client_samples(client_samples))
# 3. High-risk client details
high_risk_details = generate_high_risk_client_details(df_predictions)
if not high_risk_details.empty:
    print("\n CLIENTS À HAUT RISQUE (Retard exagéré):")
    display(high_risk_details.head(10))
else:
    print("\n Aucun client à haut risque détecté")

# ====================== END OF ADDITION ======================

import joblib
import os

# 1. Créer le dossier 'assets' s'il n'existe pas
os.makedirs('assets', exist_ok=True)

# 2. Sauvegarder le modèle LightGBM
joblib.dump(lgb_multi, 'assets/model_lgbm_multi.pkl')

# 3. Sauvegarder la liste des features utilisées lors de l'entraînement
joblib.dump(X_train_multi.columns.tolist(), 'assets/model_lgbm_multi_features.pkl')

print(" Modèle LightGBM et features sauvegardés dans le dossier 'assets/'")